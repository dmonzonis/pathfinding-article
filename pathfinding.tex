\documentclass[12pt]{report}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[parfill]{parskip}  				% Newlines create actual paragraphs
\usepackage{algorithm} 						% For pseudocode
\usepackage{algpseudocode}  					% For pseudocode
\usepackage{hyperref}						% Adds hyperlinks

% Add spacing between theorems, which is zeroed by parskip
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=\parskip \thm@postskip=0pt
}
\makeatother

% algpseudocode modifications
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\algnewcommand{\Continue}{\State \textbf{continue}}

% Theorem keyword definitions
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\title{
{Pathfinding algorithms in graphs and applications}\\
{\large Universitat de Barcelona}
}
\author{Daniel Monzon√≠s Laparra}

\begin{document}
\maketitle

\chapter*{Abstract}
Abstract goes here.

\tableofcontents

\chapter{Introduction}
Many problems in the fields of science, mathematics and engineering can be generalised to the problem of finding a path in a graph. Some examples of such problems are routing of telephone or Internet traffic, GPS routing, layout of printed circuit boards, automated theorem proving, and artificial intelligence in games and robotics. In this article, we will provide a mathematical and applied approach to this problem.

For most of the examples in the article we will be using a grid graph, represented by a tiled 2D map, in which each tile (or node) is connected to its adjacent tiles. In the map, each tile can have a different weight, or be a wall, which is impassable. This notion of weighted nodes and walls can be translated to the structure of a weighted directed graph by thinking of the weights of the tiles as the weights of the edges that connect adjacent tiles to it. Walls can be thought of as nodes that are not connected (or just non-existent) to any other node, and therefore not reachable from other nodes. A pathfinding simulator was built for this article to help illustrate these examples.

\chapter{The A* algorithm}
The A* algorithm is a very popular algorithm used in many applications to find the optimal path between two points. The algorithm works on graphs, a structure well studied in graph theory, so first we will refresh some definitions.

\begin{definition}
A \textbf{directed graph} $G$ is a pair of sets $(V, E)$, where $V$ is the set of vertices or nodes, and $E$ the set of edges, formed by pairs of vertices.
\end{definition}

\begin{definition}
A \textbf{weighted directed graph} is a graph in which $\forall e \in E \ \exists w(e) \in \mathbb{R}$. We call $w(e)$ the \textbf{weight} or \textbf{cost} of the edge $e$.

If $e = (u, v)$ for some $u, v \in V$, then we equivalently call $d(u, v) = w(e)$ the \textbf{distance} from $u$ to $v$.
\end{definition}

From now on, when we talk about a graph, we will implicitly refer to a weighted directed graph, since it's the most general type of graph we will work with. An unweighted graph can be thought of as a weighted graph where all weights are equal to one, and an undirected graph as a directed graph where $\forall (u, v) \in E,\  \exists (v, u) \in E$.

\begin{definition}[Path]
Given a graph $G$, and $u, v \in V$, a \textbf{path} $P$ between $u$ and $v$ is an ordered list of a certain amount of edges, $N$, in the form

\[ P = \{(u,v_1), (v_1, v_2), \dots, (v_{N-2}, v_{N-1}), (v_{N-1}, v)\} \]

\end{definition}

Note that paths are not unique. There may exist multiple paths between two nodes.

\begin{definition}
We say that two nodes $u, v \in V$ are connected $\Longleftrightarrow$ There exists a path $P$ between $u$ and $v$.
\end{definition}

\begin{definition}
If $u \in V$, we define the \textbf{connected component} of $u$ as
\[ C_u = \{ v \in V\ |\ u \ \text{and} \ v \ \text{are connected}\  \} \]
\end{definition}

\begin{definition}[Distance of a path]
Given a path $P$ in a weighted directed graph $G$, we define the \textbf{weight} or \textbf{distance} of the path, $dist(P)$, as

\[ d(P) = \sum_{e \in P} w(e) \]

If $P$ is a path between $u$ and $v$, we can equivalently write

\[ d_P(u, v) = d(P) \]

If the context is clear, we will just write $d(u, v)$. For convenience, if $u$ and $v$ are not connected, we define the distance between them as $d(u, v) = \infty$.
\end{definition}

Note that, in general, $d(u, v) \neq d(v, u)$, since graphs can be directed and not all paths may be reversible.

\begin{definition}[Optimal path]
\label{def:optimal}
Given a set of all the existing paths between two nodes $u$ and $v$, $X_{(u, v)}$, we will say that a path $P \in X_{(u,v)}$ is \textbf{optimal} if and only if $d(P) \le d(P') \ \forall P' \in X_{(u, v)}$.
\end{definition}

We will also say that P is the \textbf{shortest distance path} if it is optimal, and we will write the distance that fulfils the condition in definition \ref{def:optimal} as $\delta(u,v)$.


Instead of presenting the A* algorithm without any background, we will first briefly discuss some other widely known algorithms that can be used to find paths between nodes in graphs, and build up to the main algorithm by trying to gradually improve the performance.

\section{BFS}
Breadth-First Search, or BFS for short, attempts to find a path by methodically examining all the neighbours of each node it examines.

The algorithm uses a queue to keep track of the next nodes to examine, adding all unvisited neighbours of a node when it is examined, until the queue is empty. Explored nodes are kept in a set, so that we don't explore the same node twice. The queue of nodes to be explored is often called the \emph{open set}, and the set of visited nodes the \emph{closed set}.

The pseudocode for the algorithm is presented in algorithm \ref{alg:bfs}. The algorithm returns a map called \emph{previous}, which maps every node to the node we came from in the path that the algorithm computes. The procedure that we will use to reconstruct the path from this map for all algorithms is presented in algorithm \ref{alg:reconstruct}.

\begin{algorithm}
\caption{Breadth-First Search}
\label{alg:bfs}
\begin{algorithmic}[1]
\Procedure{BFS}{$G, \alpha, \beta$}
\Require Graph $G = (V, E)$, directed or undirected; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure Given $u \in G$, previous[$u$] gives us the node come from to reach $u$ in the path computed
\State Q $\gets Queue()$
\State S $\gets Set()$ \Comment{Keeps track of explored nodes}
\State previous $\gets Map()$
\For {u $\in G$}
	\State previous[u] $\gets$ null
\EndFor
\State Q.enqueue($\alpha$)
\State S.add($\alpha$)
\While {not Q.empty()}
	\State u $\gets$ Q.front()
	\State Q.dequeue()
	\For {v $\in$ u.neighbours()}
		\If {v $\not\in$ S}
			\State Q.enqueue(v)
			\State S.add(v)
			\State previous[v] $\gets$ u
		\EndIf
	\EndFor
\EndWhile
\State \Return ReconstructPath(previous, $\alpha$, $\beta$)
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Reconstruct path}
\label{alg:reconstruct}
\begin{algorithmic}[1]
\Procedure{ReconstructPath}{previous, $\alpha$, $\beta$}
\Require The map $previous$ returned by the pathfinding algorithm; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure An ordered list $P$ with the nodes from the path from $\alpha$ to $\beta$
\State $P \gets$ []  \Comment{Empty array for the path}
\State u $\gets \beta$
\While {u $\neq \alpha$}
	\State $P$.push(u)
	\State u $\gets$ previous[$\beta$]
\EndWhile
\State $P$.push($\alpha$)
\State \Return $P$.reversed()
\EndProcedure
\end{algorithmic}
\end{algorithm}

We see that with this version of BFS, all nodes in the connected component of the starting node are explored. We can improve performance if we perform an early exit, since we don't need to keep exploring once we find the end node, as shown in algorithm \ref{alg:bfs_early_exit}.

\begin{algorithm}
\caption{Breadth-First Search with early exit}
\label{alg:bfs_early_exit}
\begin{algorithmic}[1]
\Procedure{BFS}{$G, \alpha, \beta$}
\Require Graph $G = (V, E)$, directed or undirected; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure Given $u \in G$, previous[$u$] gives us the node come from to reach $u$ in the path computed, if it has been explored
\State Q $\gets Queue()$
\State S $\gets Set()$
\State previous $\gets Map()$
\For {u $\in G$}
	\State previous[u] $\gets$ null
\EndFor
\State Q.enqueue($\alpha$)
\State S.add($\alpha$)
\While {not Q.empty()}
	\State u $\gets$ Q.front()
	\State Q.dequeue()
	\For {v $\in$ u.neighbours()}
		\If {v $\not\in$ S}
			\If {v $= \beta$} \Comment{Early exit condition}
				\State \Return ReconstructPath(previous,$\alpha$,$\beta$)
			\EndIf
			\State Q.enqueue(v)
			\State S.add(v)
			\State previous[v] $\gets$ u
		\EndIf
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

Note that, even though BFS will always find a path between two nodes if they are connected, the path produced is not optimal when we consider weights. The path found will be the shortest in terms of the number of steps, but when taking into account the weights of the edges, this algorithm will not give us the shortest distance path.

%TODO Put example images

On  the other hand, the algorithm doesn't seem very efficient, since we can potentially explore lots of nodes on a very dense graph.

We will first address the optimality problem in the next algorithm, and then we will focus on efficiency.

\section{Dijkstra}
The Dijkstra algorithm is also a well known graph theory algorithm, used to find the optimal path between two nodes in a graph with positive weights. Now, instead of a simple queue, we use a priority queue. We keep exploring all unvisited neighbours of a node, but now we insert them in the priority queue using the distance of the edge.

Normally, the algorithm only gets a starting node, and computes the optimal paths to all reachable nodes from the origin, but since we're only concerned about finding the path from one specific node to another, we will use the early exit condition to end the execution as soon as we explore the goal node. We will later see that this still gives us the optimal path.

\begin{algorithm}
\caption{Dijkstra's algorithm}
\label{alg:dijkstra}
\begin{algorithmic}[1]
\Procedure{Dijkstra}{$G$, $\alpha$, $\beta$}
\Require Graph $G = (V, E)$, directed or undirected; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure Given $u \in G$, previous[$u$] gives us the node come from to reach $u$ in the path computed, and d[$u$] gives us the distance to that node, if it has been explored
\State Q $\gets PriorityQueue()$
\State S $\gets Set()$
\State d $\gets Map()$ \Comment{Keeps track of the shortest distance to each node}
\State previous $\gets Map()$
\For {u $\in G$}
	\State d[u] $\gets \infty$
	\State previous[u] $\gets$ null
\EndFor
\State Q.insert((0, $\alpha$))
\State d[$\alpha$] $\gets 0$
\While {not Q.empty()}
	\State u $\gets$ Q.removeMin()
	\State S.add(u)
	\If {u $= \beta$} \Comment{Early exit condition}
		\State \Return ReconstructPath(previous,$\alpha$,$\beta$)
	\EndIf
	\For {v $\in$ u.neighbours()}
		\If {v $\in S$}
			\Continue \Comment{Already explored node}
		\EndIf
		\State alt $\gets$ d[u] $+ w((u, v))$
		\If {alt $<$ d[v]}
			\State d[v] $\gets$ alt
			\State Q.insert((v, alt))
			\State previous[v] $\gets$ u
		\EndIf
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

We will now prove the correctness of the algorithm without the early exit condition, that is, given a node $u \in V$, the algorithm always finds the optimal path between $u$ and all other nodes $v \in V$ such that $u$ and $v$ are connected. We will do so by induction on the visited set used in algorithm \ref{alg:dijkstra}, which we will call $S$. We will also write the distance computed by Dijkstra's algorithm between two nodes $u, v$ as $d_D(u, v)$.

\begin{lemma}
\label{lemma:dijkstra}
At any given step of the algorithm, $\forall s \in S,\ d_D(u, s) = \delta(u, s)$
\end{lemma}
\begin{proof}
If $|S| = 0$, the statement is trivially true.

If $|S| = 1$, it must be $S = \{u\}$, since $S$ only grows in size, but $d_D(u, u) = 0 = \delta(u, u)$.

Now let's assume we are in an arbitrary step, and let $s$ be the current node being explored, not yet added to $S$. Let $S' = S \cup \{s\}$. By inductive hypothesis, we know that $\forall t \in S,\ d_D(u, t) = \delta(u, t)$. Now we only need to show that $d_D(u, s) = \delta(u, s)$.

Suppose that there exists a path $Q$ from $u$ to $s$ such that
\[d(Q) < d_D(u, s)\]
We know that the path $Q$ starts in $S$ (since $u \in S$), but at some point has to leave $S$ (since $s \not\in S$). Let $e = (x, y) \in Q \subset E$ be the first edge that leaves $S$, that is, $x \in S$ but $y \not\in S$. Let $Q_x \subset Q$ be the edges of $Q$ up until and without including the edge $e$. Clearly,
\[d(Q_x) + d(x, y) \le d(Q)\]

By the induction hypothesis, $d_D(u, x) = \delta(u, x) \le d(Q_x)$. Therefore,
\[ d_D(u, x) + d(x, y) \le d(Q) \]

Clearly, $\delta(u, y) \le d_D(u, x) + d(x, y)$.

Since $y \not\in S$, and since Dijkstra uses a priority queue to select the next reachable node with minimum distance, we know that $d_D(u, s) \le d_D(u, y)$.

Combining the inequalities, we get that
\[ d_D(u, s) \le d_D(u, y) \le d_D(u, x) + d(x, y) \le d(Q) < d_D(u, s) \]
which is a contradiction.

Therefore, $d_D(u, s) = \delta(u, s)$.
\end{proof}

\begin{theorem}[Correctness of Dijkstra's algorithm]
\label{thm:dijkstra}
Let $G = (V, E)$ be a weighted directed graph. Let $u \in V$. Then, after running Dijkstra's algorithm with start node $u$, the following is true
\[ \forall v \in C_u,\  d_D(u, v) = \delta(u, v) \]
\end{theorem}
\begin{proof}
We know that, at the end of Dijkstra's algorithm, we'll have explored all the nodes connected to $u$. That is, $S = C_u$. For each $v \in C_u$, apply \ref{lemma:dijkstra} to get the wanted result.
\end{proof}

Like with BFS, we can modify the algorithm to use early exit to improve performance.
\begin{lemma}
Using Dijkstra's algorithm with early exit with start node $u$ and end node $v$ ensures that $d_D(u, v) = \delta(u, v)$.alt
\end{lemma}
\begin{proof}
With early exit, when we explore node $v$ we will end the execution of the algorithm. Using \ref{lemma:dijkstra}, we know that $d_D(u, v) = \delta(u, v)$, so we already have the optimal path between the two nodes.
\end{proof}

% TODO: Talk about what happens when there are negative weights. Name Bellman-Ford algorithm.
Note that Dijkstra's algorithm only works for graphs with positive weights. For graphs with negative weights, there are other less efficient algorithms which also find optimal paths, like the Bellman-Ford algorithm.

\section{Greedy Best-First search}
As we have seen in the last section, we now have an algorithm that can find the optimal path between any two nodes in a graph with positive weights. We will now start to worry about improving the performance of the algorithms.

Let's forget about optimality for a while, and modify our pathfinding algorithm to use only an heuristic. An heuristic is a function
\begin{align*}
	h \colon V &\to \mathbb{R}\\
	u &\mapsto h(u)
\end{align*}
which gives an estimate of the true distance from a node to the goal node, which we compute without having to expand extra nodes, and varies with each type of problem we have.

We will talk more about heuristics later, but for now, let's consider what happens when we use heuristics instead of the actual distance of the paths between nodes, like we did in Dijkstra's algorithm, for the priority queue ordering. 

In Dijkstra, we used the actual distances of the paths between nodes for the priority queue ordering. Now, we will use the heuristic, so that the node closest to the goal will be the first to be explored.

\begin{algorithm}
\caption{Greedy Best-First search}
\label{alg:greedy}
\begin{algorithmic}[1]
\Procedure{GreedyBestFirstSearch}{$G$, $\alpha$, $\beta$}
\Require Graph $G = (V, E)$, directed or undirected; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure Given $u \in G$, previous[$u$] gives us the node come from to reach $u$ in the path computed, if it has been explored
\State Q $\gets PriorityQueue()$
\State S $\gets Set()$
\State previous $\gets Map()$
\For {u $\in G$}
	\State previous[u] $\gets$ null
\EndFor
\State Q.insert((0, $\alpha$))
\While {not Q.empty()}
	\State u $\gets$ queue.removeMin()
	\State S.add(u)
	\If {u $= \beta$} \Comment{Early exit condition}
		\State \Return ReconstructPath(previous,$\alpha$,$\beta$)
	\EndIf
	\For {v $\in$ u.neighbours()}
		\If {v $\in S$}
			\Continue
		\EndIf
		\State Q.insert((v, $h(v)$))
		\State previous[v] $\gets$ u
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

%TODO Define tilemap as 2d discrete map
%TODO Define manhattan distance
%\begin{definition}
%The \textbf{Manhattan distance} between two points %TODO FINISH
%\end{definition}

%TODO Talk about the problems with the greedy search

\section{A*}
As we have seen, Dijkstra always gives us optimal paths, but it wastes a lot of time exploring a lot of nodes that are not in a promising direction. On the other hand, Greedy Best-First Search explores nodes in a promising direction, but does not produce optimal paths reliably.

The A* algorithm is a combination of both algorithms. It takes into account both the actual distance from the source to a node, and the estimated distance from the node to the goal. Like Dijkstra's algorithm, it works only for positive weights.

\begin{definition}
Given a source and goal nodes in a graph $G = (V, E)$, we define the \textbf{score} as the application
\begin{align*}
	f \colon V &\to \mathbb{R}\\
	u &\mapsto f(u) = g(u) + h(u)
\end{align*}
where $g(u)$ is the exact cost of the path from the source to the node $u$ that the algorithm currently has, and $h(u)$ is the heuristic, which is an estimate of the distance from the node $u$ to the goal.
We will call $g$ the \textbf{g-score}, and $h$ the \textbf{h-score}.
\end{definition}

When a node is explored, its g- score, and thus its score will be updated. The pseudocode for the algorithm is shown in algorithm \ref{alg:astar}. As we can see, it's very similar to Dijkstra's, except that we now use the score for the priority queue ordering, instead of just the distance to that node.

This new algorithm is faster than Dijkstra, but it only finds optimal paths within a certain condition, which is what we will prove next.

\begin{definition}
A heuristic function $h$ is said to be \textbf{admissible} if, $\forall u \in V$, $h(u)$ never overestimates the real cost of moving from $u$ to the goal, that is, if $P_u$ is an optimal path from $u$ to the goal, then $\forall u \in V \ h(u) \le d(P_u)$.
\end{definition}



\begin{algorithm}
\caption{A* algorithm}
\label{alg:astar}
\begin{algorithmic}[1]
\Procedure{AStar}{$G$, $\alpha$, $\beta$}
\Require Graph $G = (V, E)$, directed or undirected; source node $\alpha \in V$; goal node $\beta \in V$
\Ensure Given $u \in G$, previous[$u$] gives us the node come from to reach $u$ in the path computed, and g[$u$] is the current g-score of the node
\State Q $\gets PriorityQueue()$
\State S $\gets Set()$
\State g $\gets Map()$
\State previous $\gets Map()$
\For {u $\in G$}
	\State g[u] $\gets \infty$
	\State previous[u] $\gets$ null
\EndFor
\State Q.insert((0, $\alpha$))
\State g[$\alpha$] $\gets 0$
\While {not Q.empty()}
	\State u $\gets$ Q.removeMin()
	\State S.add(u)
	\If {u $= \beta$} \Comment{Early exit condition}
		\State \Return ReconstructPath(previous,$\alpha$,$\beta$)
	\EndIf
	\For {v $\in$ u.neighbours()}
		\If {v $\in S$}
			\Continue \Comment{Already explored node}
		\EndIf
		\State alt $\gets$ g[u] $+ w((u, v))$
		\If {alt $<$ g[v]}
			\State g[v] $\gets$ alt \Comment{Update the g-score}
			\State $f = g[v] + h(v)$
			\State Q.insert((v, f))
			\State previous[v] $\gets$ u
		\EndIf
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}


\chapter{Heuristics}
Maybe a short chapter about heuristics?

\chapter{A* variants}
Explain in detail some of the A* variants and how they improve the original algorithm.

\end{document}
